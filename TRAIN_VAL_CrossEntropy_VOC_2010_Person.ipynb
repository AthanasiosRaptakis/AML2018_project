{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.optim\n",
    "import torch.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from include.data import ObjectSegmentationDataset\n",
    "from include.hybrid_net_batchnorm import SegmentationModel\n",
    "\n",
    "from include.Utility_Functions import Validate_IOU\n",
    "from torch.nn.modules.upsampling import Upsample\n",
    "\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from include import crf\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loaders for Training and Validation\n",
    "\n",
    "# It is important to normalise the Input images acording to\n",
    "# https://pytorch.org/docs/stable/torchvision/models.html\n",
    "\n",
    "norm_transform = transforms.Normalize(mean=[0.4441137029691302,0.4153741837809971,0.38574530437912646],std=[0.2804474648193802,0.2737859518590525,0.2825218670683551])\n",
    "transform = transforms.Compose([transforms.ToTensor(),norm_transform])\n",
    "number_of_classes = 7\n",
    "train_dataset = ObjectSegmentationDataset(\n",
    "    src_image_dir=\"/home/snajder/AML/data/VOCdevkit/VOC2012/JPEGImages\",\n",
    "    seg_image_dir=\"/home/snajder/AML/data/VOCdevkit/VOC2010/person_trainval/Annotations_Part_images\",\n",
    "    num_classes=number_of_classes,\n",
    "    transform=transform,\n",
    "    gt_one_hot=False,\n",
    "    rescale=False)\n",
    "\n",
    "val_dataset = ObjectSegmentationDataset(\n",
    "    src_image_dir=\"/home/snajder/AML/data/VOCdevkit/VOC2012/JPEGImages\",\n",
    "    seg_image_dir=\"/home/snajder/AML/data/VOCdevkit/VOC2010/person_trainval/Annotations_Part_images\",\n",
    "    num_classes=number_of_classes,\n",
    "    transform=transform,\n",
    "    gt_one_hot=False,\n",
    "    augment=False,\n",
    "    rescale=False)    \n",
    "\n",
    "# Must match augmentation options above. If augmentation=False, this is 1, \n",
    "# if augmentation=True and rescale=True then this is 4\n",
    "# if augmentation=True and rescale=False then this is 8\n",
    "augmentation_factor = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SegmentationModel(num_classes=7)\n",
    "net_file=\"Segnet_Best_params_VOC_Person_7class_09-16.pth\"\n",
    "checkpoint = torch.load(net_file)\n",
    "net.load_state_dict(checkpoint['state_dict'])\n",
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=1\n",
    "\n",
    "best_score=0\n",
    "\n",
    "net.train()\n",
    "running_loss=0.0\n",
    "losses=[]\n",
    "Val_Score=[]\n",
    "\n",
    "# Create training and validation loader for cross validation\n",
    "# Now this is a bit complicated, because we don't want to separate images\n",
    "# from their augmented versions. For example, if image 0 is in the validation\n",
    "# set, then image 1 (which would be image 0 horizontally flipped) should not\n",
    "# be in the training set. Hence, we first pick indices from the number of \n",
    "# images without augmentations, then  multiply all indices by the number of\n",
    "# augmentations and add the augmented indices back for the training set\n",
    "\n",
    "num_train = len(train_dataset)\n",
    "# Indices of images (NOT considering the augmentations)\n",
    "indices = list(range(num_train//augmentation_factor))\n",
    "num_validation = 500\n",
    "num_test = 250\n",
    "\n",
    "np.random.seed(43)\n",
    "validation_idx = np.random.choice(indices, size=num_validation, replace=False)\n",
    "train_idx = list(set(indices) - set(validation_idx))\n",
    "test_idx = np.random.choice(train_idx, size=num_test, replace=False)\n",
    "train_idx = list(set(train_idx) - set(validation_idx))\n",
    "np.random.seed(int(time.time()))\n",
    "\n",
    "# add indices of augmentations\n",
    "train_idx = [idx * augmentation_factor + aug_offset for idx in train_idx for aug_offset in range(augmentation_factor)]\n",
    "\n",
    "\n",
    "Train_Loader = torch.utils.data.DataLoader(train_dataset, batch_size=bs, shuffle=False,\n",
    "                                         num_workers=4, sampler=SubsetRandomSampler(train_idx))\n",
    "VAL_Loader = torch.utils.data.DataLoader(val_dataset, batch_size=1, shuffle=False, \n",
    "                                         num_workers=4, sampler=SubsetRandomSampler(validation_idx))\n",
    "Test_Loader = torch.utils.data.DataLoader(val_dataset, batch_size=1, shuffle=False, \n",
    "                                         num_workers=4, sampler=SubsetRandomSampler(test_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This code has been used to train batches of downscaled images in the first stages of training\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "\n",
    "optimizer = optim.SGD([\n",
    "                {'params': net.vgg.parameters(), 'lr': learning_rate*0.1},\n",
    "                {'params': net.atr.parameters(), 'lr': learning_rate}\n",
    "            ], momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "for epoch in range(2000):\n",
    "    iterations = 0\n",
    "    net.train()\n",
    "    for i, data in enumerate(Train_Loader, 0):\n",
    "        src_img, seg_img, seg_img_ds, src_img_raw = data\n",
    "\n",
    "        Input = Variable(src_img).float().cuda()\n",
    "        Target = Variable(seg_img_ds.long(), requires_grad=False).cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        Output = net(Input)\n",
    "\n",
    "        # use weighted cross entropy\n",
    "        ps = nn.functional.softmax(Output, dim=1).sum(dim=(0,2,3))\n",
    "        weights = (Target.view(-1).size()[0] - ps)/ps\n",
    "        loss = nn.functional.cross_entropy(Output, Target, weight=weights.detach())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss=(loss.cpu().data)/Output.shape[0]\n",
    "        \n",
    "        iterations+=bs\n",
    "            \n",
    "\n",
    "        if iterations % 50 == 0: \n",
    "            print('Epoch = %d, Iteration = %d, loss= %.3f' % (epoch + 1, iterations, running_loss))    \n",
    "            out=nn.functional.softmax(Output[-1,:,:,:], dim=0)\n",
    "            out=out.cpu()\n",
    "            out=out.detach().numpy()\n",
    "\n",
    "            I=np.argmax(out,axis=0)\n",
    "            fig = plt.figure()\n",
    "            fig.add_subplot(1,3,1)\n",
    "            plt.imshow(src_img_raw[-1].numpy())\n",
    "            fig.add_subplot(1,3,2)\n",
    "            plt.imshow(seg_img_ds[-1].numpy())\n",
    "            plt.axis('off')\n",
    "            fig.add_subplot(1,3,3)\n",
    "            plt.imshow(I[:,:])\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "            \n",
    "    net.eval() \n",
    "    # Checkpoint Network and Optimiser after each epoch\n",
    "    best_score,score=Validate_IOU(net,optimizer,epoch,losses,Val_Score,bs,learning_rate,VAL_Loader,best_score,net_file)\n",
    "    print(\"Current validation score: \", score)\n",
    "    losses.append(running_loss)\n",
    "    Val_Score.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code has been used in later stages of the training. Instead of batchwise training, \n",
    "# it assumes batches of size 1, but runs multiple batches in sequence before taking a step\n",
    "# in the optimizer. This reduces the noise level in the gradient descent, while allowing \n",
    "# for images of variable size\n",
    "\n",
    "\n",
    "learning_rate = 5e-4\n",
    "\n",
    "v_bs = 3\n",
    "optimizer = optim.SGD([\n",
    "                {'params': net.vgg.parameters(), 'lr': learning_rate*0.1},\n",
    "                {'params': net.atr.parameters(), 'lr': learning_rate}\n",
    "            ], momentum=0.91, weight_decay=0.0006)\n",
    "\n",
    "for epoch in range(2000):\n",
    "    iterations = 0\n",
    "    net.train()\n",
    "    \n",
    "    batch_loss = 0\n",
    "    for i, data in enumerate(Train_Loader, 0):\n",
    "        src_img, seg_img, seg_img_ds, src_img_raw = data\n",
    "\n",
    "        Input = Variable(src_img).float().cuda()\n",
    "        Target = Variable(seg_img_ds.long(), requires_grad=False).cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        Output = net(Input)\n",
    "\n",
    "        # use weighted cross entropy\n",
    "        ps = nn.functional.softmax(Output, dim=1).sum(dim=(0,2,3))\n",
    "        weights = (Target.view(-1).size()[0] - ps)/ps\n",
    "        loss = nn.functional.cross_entropy(Output, Target, weight=weights.detach())\n",
    "        batch_loss = batch_loss + loss\n",
    "        iterations+=bs\n",
    "        \n",
    "        if(iterations % v_bs == v_bs - 1):\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss=(batch_loss.cpu().data)/v_bs\n",
    "\n",
    "\n",
    "            if i % 50 == 0: \n",
    "                print('Epoch = %d, Iteration = %d, loss= %.3f' % (epoch + 1, iterations, running_loss))    \n",
    "                out=nn.functional.softmax(Output[-1,:,:,:], dim=0)\n",
    "                out=out.cpu()\n",
    "                out=out.detach().numpy()\n",
    "\n",
    "                I=np.argmax(out,axis=0)\n",
    "                fig = plt.figure()\n",
    "                fig.add_subplot(1,3,1)\n",
    "                plt.imshow(src_img_raw[-1].numpy())\n",
    "                fig.add_subplot(1,3,2)\n",
    "                plt.imshow(seg_img_ds[-1].numpy())\n",
    "                plt.axis('off')\n",
    "                fig.add_subplot(1,3,3)\n",
    "                plt.imshow(I[:,:])\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "            batch_loss = 0\n",
    "            \n",
    "    net.eval() \n",
    "    # Checkpoint Network and Optimiser after each epoch\n",
    "    best_score,score=Validate_IOU(net,optimizer,epoch,losses,Val_Score,bs,learning_rate,VAL_Loader,best_score,net_file)\n",
    "    print(\"Current validation score: \", score)\n",
    "    losses.append(running_loss)\n",
    "    Val_Score.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize how well it works on the validation set\n",
    "net.eval()\n",
    "for i, data in enumerate(VAL_Loader, 0):\n",
    "        src_img, seg_img, seg_img_ds, src_img_raw = data\n",
    "\n",
    "        Input = Variable(src_img).float().cuda()\n",
    "        Target = Variable(seg_img_ds.long(), requires_grad=False).cuda()\n",
    "        \n",
    "        Output = net(Input)\n",
    "        out=nn.functional.softmax(Output[-1,:,:,:], dim=0)\n",
    "        out=out.cpu()\n",
    "        out=out.detach().numpy()\n",
    "\n",
    "        I=np.argmax(out,axis=0)\n",
    "        fig = plt.figure()\n",
    "        fig.add_subplot(1,3,1)\n",
    "        plt.imshow(np.transpose(src_img[-1].numpy(), axes=(1,2,0)))\n",
    "        fig.add_subplot(1,3,2)\n",
    "        plt.imshow(seg_img_ds[-1].numpy())\n",
    "        #plt.imshow(np.argmax(seg_img_ds[-1].numpy(), axis=0))\n",
    "        plt.axis('off')\n",
    "        fig.add_subplot(1,3,3)\n",
    "        plt.imshow(I[:,:])\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to test some visualization of the CRF\n",
    "en = enumerate(Train_Loader, 0)\n",
    "\n",
    "test_input, test_gt, test_gt_ds, test_input_raw = next(en)[1]\n",
    "test_input_raw = test_input_raw[0].clone()\n",
    "test_gt = test_gt[0]\n",
    "test_gt_ds = test_gt_ds[0]\n",
    "test_input = test_input.cuda()\n",
    "m = nn.Upsample(size=(test_input.shape[2],test_input.shape[3]), mode='bilinear', align_corners=True)\n",
    "test_out = net(test_input)[0]\n",
    "test_out = nn.functional.softmax(test_out[:,:,:], dim=0)\n",
    "test_out = test_out[:,:,:]\n",
    "test_out_upsampled = m(test_out.unsqueeze(0)).cpu()\n",
    "_, test_out_labels = test_out_upsampled[0].max(dim=0)\n",
    "\n",
    "unary_ori = test_out_upsampled[0].cpu().detach().numpy()\n",
    "unary = unary_ori.reshape((7,-1))\n",
    "unary = - np.log(unary)\n",
    "image = (test_input_raw*255).byte().cpu().detach().numpy()\n",
    "#image = np.transpose(image, axes=(1,2,0)).copy()\n",
    "after_crf = crf.applyDenseCRF(unary, image,70,5,3,5,3)\n",
    "#after_crf = np.log(after_crf)\n",
    "after_crf = np.array(after_crf).reshape(7,image.shape[0],image.shape[1])\n",
    "unary = unary.reshape(7,image.shape[0],image.shape[1])\n",
    "\n",
    "for part in range(7):\n",
    "    print(\"Part \",part)\n",
    "    plt.imshow(unary_ori[part])\n",
    "    plt.show()\n",
    "    plt.imshow(after_crf[part])\n",
    "    plt.show()\n",
    "\n",
    "plt.imshow(test_gt.numpy())\n",
    "plt.show()\n",
    "plt.imshow(np.argmax(unary_ori,axis=0))\n",
    "plt.show()\n",
    "plt.imshow(np.argmax(after_crf,axis=0))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
